//! SIMD-accelerated sRGB ↔ linear conversion.
//!
//! This module provides high-performance conversion functions using AVX2/SSE SIMD
//! instructions via the `wide` crate with runtime CPU feature detection.
//!
//! # API Overview
//!
//! ## x8 Functions (process 8 values at once)
//! - `srgb_to_linear_x8` - f32x8 sRGB → f32x8 linear
//! - `linear_to_srgb_x8` - f32x8 linear → f32x8 sRGB
//! - `srgb_u8_to_linear_x8` - \[u8; 8\] sRGB → f32x8 linear
//! - `linear_to_srgb_u8_x8` - f32x8 linear → \[u8; 8\] sRGB
//!
//! ## Slice Functions (process entire slices)
//! - `srgb_to_linear_slice` - &mut \[f32\] sRGB → linear in-place
//! - `linear_to_srgb_slice` - &mut \[f32\] linear → sRGB in-place
//! - `srgb_u8_to_linear_slice` - &\[u8\] sRGB → &mut \[f32\] linear
//! - `linear_to_srgb_u8_slice` - &\[f32\] linear → &mut \[u8\] sRGB

#[cfg(target_arch = "x86_64")]
use archmage::{Desktop64, arcane, rite};
use archmage::{ScalarToken, incant};
use wide::{CmpLt, f32x8};

use crate::fast_math::pow_x8;

// Alias magetypes f32x8 to avoid name clash with wide::f32x8
#[cfg(target_arch = "x86_64")]
use magetypes::simd::f32x8 as mt_f32x8;

// sRGB transfer function constants (C0-continuous, moxcms-derived)
// These ensure exact continuity at the linear/power segment junction.
// Standard IEC values (0.055, 1.055, 0.04045) have a tiny discontinuity.
const SRGB_LINEAR_THRESHOLD: f32x8 = f32x8::splat(0.039_293_37);
const LINEAR_THRESHOLD: f32x8 = f32x8::splat(0.003_041_282_6);
const LINEAR_SCALE: f32x8 = f32x8::splat(1.0 / 12.92);
const TWELVE_92: f32x8 = f32x8::splat(12.92);
const ZERO: f32x8 = f32x8::splat(0.0);
const ONE: f32x8 = f32x8::splat(1.0);
const HALF: f32x8 = f32x8::splat(0.5);

/// Precomputed sRGB u8 → linear f32 lookup table.
/// Uses the same constants as the transfer module (C0-continuous IEC 61966-2-1).
/// Generated by computing `srgb_u8_to_linear(i)` for each i in 0..=255.
/// To regenerate: `cargo run --release --example generate_lut`
const SRGB_U8_TO_LINEAR_LUT: [f32; 256] = [
    0.0_f32,
    0.000303527_f32,
    0.000607054_f32,
    0.000910581_f32,
    0.001214108_f32,
    0.001517635_f32,
    0.001821162_f32,
    0.0021246888_f32,
    0.002428216_f32,
    0.002731743_f32,
    0.00303527_f32,
    0.0033473307_f32,
    0.0036773437_f32,
    0.0040255957_f32,
    0.004392362_f32,
    0.004777916_f32,
    0.0051825214_f32,
    0.00560644_f32,
    0.006049924_f32,
    0.0065132244_f32,
    0.0069965874_f32,
    0.007500253_f32,
    0.008024457_f32,
    0.008569433_f32,
    0.009135411_f32,
    0.009722613_f32,
    0.010331264_f32,
    0.010961577_f32,
    0.011613773_f32,
    0.012288062_f32,
    0.012984648_f32,
    0.013703744_f32,
    0.01444555_f32,
    0.015210266_f32,
    0.01599809_f32,
    0.016809216_f32,
    0.01764384_f32,
    0.018502146_f32,
    0.019384334_f32,
    0.02029058_f32,
    0.02122107_f32,
    0.022175988_f32,
    0.023155512_f32,
    0.024159823_f32,
    0.025189094_f32,
    0.026243499_f32,
    0.027323212_f32,
    0.0284284_f32,
    0.02955924_f32,
    0.030715894_f32,
    0.03189852_f32,
    0.0331073_f32,
    0.034342386_f32,
    0.03560393_f32,
    0.036892105_f32,
    0.03820707_f32,
    0.039548974_f32,
    0.04091798_f32,
    0.04231424_f32,
    0.04373789_f32,
    0.045189105_f32,
    0.04666803_f32,
    0.04817481_f32,
    0.049709592_f32,
    0.051272515_f32,
    0.052863743_f32,
    0.054483414_f32,
    0.05613167_f32,
    0.05780865_f32,
    0.05951448_f32,
    0.061249338_f32,
    0.063013345_f32,
    0.06480663_f32,
    0.06662934_f32,
    0.068481594_f32,
    0.07036356_f32,
    0.072275355_f32,
    0.07421711_f32,
    0.07618896_f32,
    0.07819102_f32,
    0.080223456_f32,
    0.08228638_f32,
    0.08437992_f32,
    0.086504206_f32,
    0.088659346_f32,
    0.09084551_f32,
    0.093062796_f32,
    0.09531133_f32,
    0.09759124_f32,
    0.09990266_f32,
    0.10224568_f32,
    0.104620464_f32,
    0.10702711_f32,
    0.109465756_f32,
    0.1119365_f32,
    0.11443946_f32,
    0.116974786_f32,
    0.11954258_f32,
    0.12214295_f32,
    0.12477602_f32,
    0.1274419_f32,
    0.13014072_f32,
    0.1328726_f32,
    0.13563763_f32,
    0.13843594_f32,
    0.14126763_f32,
    0.14413282_f32,
    0.14703165_f32,
    0.1499642_f32,
    0.15293059_f32,
    0.15593089_f32,
    0.15896529_f32,
    0.16203386_f32,
    0.1651367_f32,
    0.16827393_f32,
    0.17144562_f32,
    0.17465195_f32,
    0.17789298_f32,
    0.18116882_f32,
    0.1844796_f32,
    0.18782537_f32,
    0.1912063_f32,
    0.19462249_f32,
    0.19807397_f32,
    0.2015609_f32,
    0.20508343_f32,
    0.20864154_f32,
    0.21223548_f32,
    0.21586527_f32,
    0.21953095_f32,
    0.22323275_f32,
    0.22697066_f32,
    0.23074481_f32,
    0.2345554_f32,
    0.23840237_f32,
    0.24228595_f32,
    0.24620613_f32,
    0.25016314_f32,
    0.25415692_f32,
    0.25818765_f32,
    0.26225552_f32,
    0.26636043_f32,
    0.27050266_f32,
    0.27468216_f32,
    0.27889907_f32,
    0.2831536_f32,
    0.28744566_f32,
    0.29177552_f32,
    0.2961431_f32,
    0.30054858_f32,
    0.30499217_f32,
    0.30947372_f32,
    0.31399357_f32,
    0.3185516_f32,
    0.32314798_f32,
    0.3277829_f32,
    0.33245632_f32,
    0.33716843_f32,
    0.34191918_f32,
    0.34670877_f32,
    0.35153738_f32,
    0.35640487_f32,
    0.36131153_f32,
    0.3662573_f32,
    0.37124234_f32,
    0.37626684_f32,
    0.38133067_f32,
    0.3864341_f32,
    0.39157712_f32,
    0.3967598_f32,
    0.4019824_f32,
    0.40724477_f32,
    0.4125472_f32,
    0.41788962_f32,
    0.42327216_f32,
    0.42869502_f32,
    0.4341581_f32,
    0.43966165_f32,
    0.44520563_f32,
    0.45079017_f32,
    0.4564154_f32,
    0.46208134_f32,
    0.46778816_f32,
    0.4735358_f32,
    0.47932443_f32,
    0.4851542_f32,
    0.49102503_f32,
    0.49693722_f32,
    0.5028906_f32,
    0.5088854_f32,
    0.5149218_f32,
    0.5209996_f32,
    0.52711916_f32,
    0.5332804_f32,
    0.53948337_f32,
    0.5457284_f32,
    0.55201524_f32,
    0.55834424_f32,
    0.56471527_f32,
    0.57112855_f32,
    0.57758415_f32,
    0.58408207_f32,
    0.5906225_f32,
    0.59720534_f32,
    0.6038308_f32,
    0.6104991_f32,
    0.61721_f32,
    0.62396383_f32,
    0.6307605_f32,
    0.6376001_f32,
    0.644483_f32,
    0.6514088_f32,
    0.658378_f32,
    0.6653904_f32,
    0.67244613_f32,
    0.67954546_f32,
    0.68668824_f32,
    0.6938747_f32,
    0.7011047_f32,
    0.7083785_f32,
    0.7156962_f32,
    0.72305775_f32,
    0.7304634_f32,
    0.73791295_f32,
    0.7454066_f32,
    0.75294465_f32,
    0.76052684_f32,
    0.7681535_f32,
    0.7758244_f32,
    0.7835399_f32,
    0.79130006_f32,
    0.79910475_f32,
    0.80695426_f32,
    0.8148484_f32,
    0.82278764_f32,
    0.8307716_f32,
    0.83880067_f32,
    0.8468749_f32,
    0.8549941_f32,
    0.8631587_f32,
    0.8713685_f32,
    0.87962353_f32,
    0.8879244_f32,
    0.89627033_f32,
    0.9046623_f32,
    0.9130995_f32,
    0.9215827_f32,
    0.9301116_f32,
    0.93868643_f32,
    0.9473071_f32,
    0.9559739_f32,
    0.9646866_f32,
    0.9734457_f32,
    0.9822507_f32,
    0.9911024_f32,
    1.0_f32,
];

#[inline]
fn get_lut() -> &'static [f32; 256] {
    &SRGB_U8_TO_LINEAR_LUT
}

/// Convert a single sRGB u8 value to linear f32 using LUT lookup.
///
/// This is the fastest method for u8 input as it uses a precomputed lookup table
/// embedded in the binary. For batch conversions, use [`srgb_u8_to_linear_slice`].
///
/// # Example
/// ```
/// use linear_srgb::simd::srgb_u8_to_linear;
///
/// let linear = srgb_u8_to_linear(128);
/// assert!((linear - 0.2158).abs() < 0.001);
/// ```
#[inline]
pub fn srgb_u8_to_linear(value: u8) -> f32 {
    get_lut()[value as usize]
}

// ============================================================================
// x8 Inline Functions - Always inlined, for use in caller's magetypes code
// ============================================================================

/// Convert 8 sRGB f32 values to linear (always inlined).
///
/// Use this variant inside your own `#[magetypes]` functions to avoid
/// double dispatch overhead. For standalone calls, use [`srgb_to_linear_x8_dispatch`].
///
/// Input values are clamped to \[0, 1\].
#[inline(always)]
pub fn srgb_to_linear_x8_inline(srgb: f32x8) -> f32x8 {
    let srgb = srgb.max(ZERO).min(ONE);
    let linear_result = srgb * LINEAR_SCALE;

    // Degree-11 Chebyshev polynomial (Estrin evaluation)
    let u = srgb.mul_add(f32x8::splat(S2L_INV_HW), f32x8::splat(S2L_BIAS));
    let u2 = u * u;
    let u4 = u2 * u2;
    let u_8 = u4 * u4;
    let p01 = f32x8::splat(S2L_C1).mul_add(u, f32x8::splat(S2L_C0));
    let p23 = f32x8::splat(S2L_C3).mul_add(u, f32x8::splat(S2L_C2));
    let p45 = f32x8::splat(S2L_C5).mul_add(u, f32x8::splat(S2L_C4));
    let p67 = f32x8::splat(S2L_C7).mul_add(u, f32x8::splat(S2L_C6));
    let p89 = f32x8::splat(S2L_C9).mul_add(u, f32x8::splat(S2L_C8));
    let pab = f32x8::splat(S2L_C11).mul_add(u, f32x8::splat(S2L_C10));
    let p0123 = p23.mul_add(u2, p01);
    let p4567 = p67.mul_add(u2, p45);
    let p8_11 = pab.mul_add(u2, p89);
    let p0_7 = p4567.mul_add(u4, p0123);
    let power_result = p8_11.mul_add(u_8, p0_7);

    let mask = srgb.simd_lt(SRGB_LINEAR_THRESHOLD);
    mask.blend(linear_result, power_result)
}

/// Convert 8 linear f32 values to sRGB (always inlined).
///
/// Use this variant inside your own `#[magetypes]` functions to avoid
/// double dispatch overhead. For standalone calls, use [`linear_to_srgb_x8_dispatch`].
///
/// Input values are clamped to \[0, 1\].
#[inline(always)]
pub fn linear_to_srgb_x8_inline(linear: f32x8) -> f32x8 {
    let linear = linear.max(ZERO).min(ONE);
    let linear_result = linear * TWELVE_92;

    // sqrt transform + degree-15 Chebyshev polynomial (Estrin evaluation)
    let s = linear.sqrt();
    let u = s.mul_add(f32x8::splat(L2S_INV_HW), f32x8::splat(L2S_BIAS));
    let u2 = u * u;
    let u4 = u2 * u2;
    let u_8 = u4 * u4;
    let p01 = f32x8::splat(L2S_C1).mul_add(u, f32x8::splat(L2S_C0));
    let p23 = f32x8::splat(L2S_C3).mul_add(u, f32x8::splat(L2S_C2));
    let p45 = f32x8::splat(L2S_C5).mul_add(u, f32x8::splat(L2S_C4));
    let p67 = f32x8::splat(L2S_C7).mul_add(u, f32x8::splat(L2S_C6));
    let p89 = f32x8::splat(L2S_C9).mul_add(u, f32x8::splat(L2S_C8));
    let pab = f32x8::splat(L2S_C11).mul_add(u, f32x8::splat(L2S_C10));
    let pcd = f32x8::splat(L2S_C13).mul_add(u, f32x8::splat(L2S_C12));
    let pef = f32x8::splat(L2S_C15).mul_add(u, f32x8::splat(L2S_C14));
    let p0123 = p23.mul_add(u2, p01);
    let p4567 = p67.mul_add(u2, p45);
    let p89ab = pab.mul_add(u2, p89);
    let pcdef = pef.mul_add(u2, pcd);
    let p0_7 = p4567.mul_add(u4, p0123);
    let p8_f = pcdef.mul_add(u4, p89ab);
    let power_result = p8_f.mul_add(u_8, p0_7);

    let mask = linear.simd_lt(LINEAR_THRESHOLD);
    mask.blend(linear_result, power_result)
}

/// Convert 8 linear f32 values to sRGB u8 (always inlined).
///
/// Uses a 4096-entry const LUT for direct lookup — no pow/log/exp computation.
/// Max error: ±1 u8 level (same as the SIMD polynomial path).
#[inline(always)]
pub fn linear_to_srgb_u8_x8_inline(linear: f32x8) -> [u8; 8] {
    linear_to_srgb_u8_lut_x8(linear)
}

/// Convert 8 linear f32 values to sRGB u8 using const LUT.
///
/// Clamps to [0,1], scales to LUT index, does 8 scalar lookups from
/// a 4KB table (fits L1 cache). No pow/exp/log computation.
#[inline(always)]
pub(crate) fn linear_to_srgb_u8_lut_x8(linear: f32x8) -> [u8; 8] {
    let clamped = linear.max(ZERO).min(ONE);
    let scaled = clamped * f32x8::splat(4095.0) + HALF;
    let arr: [f32; 8] = scaled.into();
    let lut = &crate::const_luts::LINEAR_TO_SRGB_U8;
    [
        lut[arr[0] as usize & 0xFFF],
        lut[arr[1] as usize & 0xFFF],
        lut[arr[2] as usize & 0xFFF],
        lut[arr[3] as usize & 0xFFF],
        lut[arr[4] as usize & 0xFFF],
        lut[arr[5] as usize & 0xFFF],
        lut[arr[6] as usize & 0xFFF],
        lut[arr[7] as usize & 0xFFF],
    ]
}

/// Convert 8 gamma-encoded f32 values to linear (always inlined).
///
/// Use this variant inside your own `#[magetypes]` functions to avoid
/// double dispatch overhead.
#[inline(always)]
pub fn gamma_to_linear_x8_inline(encoded: f32x8, gamma: f32) -> f32x8 {
    let encoded = encoded.max(ZERO).min(ONE);
    pow_x8(encoded, gamma)
}

/// Convert 8 linear f32 values to gamma-encoded (always inlined).
///
/// Use this variant inside your own `#[magetypes]` functions to avoid
/// double dispatch overhead.
#[inline(always)]
pub fn linear_to_gamma_x8_inline(linear: f32x8, gamma: f32) -> f32x8 {
    let linear = linear.max(ZERO).min(ONE);
    pow_x8(linear, 1.0 / gamma)
}

// ============================================================================
// magetypes #[rite] helpers (x86-64 only) — real AVX2+FMA SIMD
// ============================================================================

// sRGB transfer function scalar constants (for magetypes which needs token-gated splat)
#[cfg(target_arch = "x86_64")]
const MT_SRGB_LINEAR_THRESHOLD: f32 = 0.039_293_37;
#[cfg(target_arch = "x86_64")]
const MT_LINEAR_THRESHOLD: f32 = 0.003_041_282_6;
#[cfg(target_arch = "x86_64")]
const MT_LINEAR_SCALE: f32 = 1.0 / 12.92;
#[cfg(target_arch = "x86_64")]
const MT_TWELVE_92: f32 = 12.92;

// sRGB→linear degree-11 Chebyshev polynomial (Estrin's scheme)
// Approximates ((s + offset) / scale)^2.4 on [threshold, 1.0]
// u = s * INV_HW + BIAS maps [threshold, 1] → [-1, 1]
const S2L_INV_HW: f32 = 2.081_801;
const S2L_BIAS: f32 = -1.081_800_9;
const S2L_C0: f32 = 2.326_832_7e-1;
const S2L_C1: f32 = 4.667_970_8e-1;
const S2L_C2: f32 = 2.731_341e-1;
const S2L_C3: f32 = 3.044_251_2e-2;
const S2L_C4: f32 = -3.802_638_5e-3;
const S2L_C5: f32 = 1.011_499_3e-3;
const S2L_C6: f32 = -4.267_19e-4;
const S2L_C7: f32 = 1.966_666_5e-4;
const S2L_C8: f32 = 2.025_719_4e-5;
const S2L_C9: f32 = -2.400_594_3e-5;
const S2L_C10: f32 = -8.762_017e-5;
const S2L_C11: f32 = 5.557_536_5e-5;

// linear→sRGB degree-15 Chebyshev polynomial via sqrt transform (Estrin's scheme)
// Approximates scale * (√l)^(5/6) - offset on [sqrt(threshold), 1.0]
// u = √l * INV_HW + BIAS maps [sqrt(threshold), 1] → [-1, 1]
const L2S_INV_HW: f32 = 2.116_733_3;
const L2S_BIAS: f32 = -1.116_733_2;
const L2S_C0: f32 = 5.641_828e-1;
const L2S_C1: f32 = 4.620_569_3e-1;
const L2S_C2: f32 = -3.450_065e-2;
const L2S_C3: f32 = 1.202_464_2e-2;
const L2S_C4: f32 = -5.398_721e-3;
const L2S_C5: f32 = 2.946_610_3e-3;
const L2S_C6: f32 = -5.274_399_6e-3;
const L2S_C7: f32 = 4.055_202e-3;
const L2S_C8: f32 = 1.062_489_9e-2;
const L2S_C9: f32 = -9.012_202e-3;
const L2S_C10: f32 = -2.186_026_6e-2;
const L2S_C11: f32 = 1.824_478_4e-2;
const L2S_C12: f32 = 1.958_387_2e-2;
const L2S_C13: f32 = -1.638_288e-2;
const L2S_C14: f32 = -7.710_282_7e-3;
const L2S_C15: f32 = 6.419_743e-3;

#[cfg(target_arch = "x86_64")]
#[rite]
fn srgb_to_linear_mt(token: Desktop64, srgb: mt_f32x8) -> mt_f32x8 {
    let zero = mt_f32x8::zero(token);
    let one = mt_f32x8::splat(token, 1.0);
    let srgb = srgb.max(zero).min(one);

    let linear_result = srgb * mt_f32x8::splat(token, MT_LINEAR_SCALE);

    // Degree-11 Chebyshev polynomial (Estrin evaluation)
    let u = srgb.mul_add(
        mt_f32x8::splat(token, S2L_INV_HW),
        mt_f32x8::splat(token, S2L_BIAS),
    );
    let u2 = u * u;
    let u4 = u2 * u2;
    let u_8 = u4 * u4;
    let p01 = mt_f32x8::splat(token, S2L_C1).mul_add(u, mt_f32x8::splat(token, S2L_C0));
    let p23 = mt_f32x8::splat(token, S2L_C3).mul_add(u, mt_f32x8::splat(token, S2L_C2));
    let p45 = mt_f32x8::splat(token, S2L_C5).mul_add(u, mt_f32x8::splat(token, S2L_C4));
    let p67 = mt_f32x8::splat(token, S2L_C7).mul_add(u, mt_f32x8::splat(token, S2L_C6));
    let p89 = mt_f32x8::splat(token, S2L_C9).mul_add(u, mt_f32x8::splat(token, S2L_C8));
    let pab = mt_f32x8::splat(token, S2L_C11).mul_add(u, mt_f32x8::splat(token, S2L_C10));
    let p0123 = p23.mul_add(u2, p01);
    let p4567 = p67.mul_add(u2, p45);
    let p8_11 = pab.mul_add(u2, p89);
    let p0_7 = p4567.mul_add(u4, p0123);
    let power_result = p8_11.mul_add(u_8, p0_7);

    let mask = srgb.simd_lt(mt_f32x8::splat(token, MT_SRGB_LINEAR_THRESHOLD));
    mt_f32x8::blend(mask, linear_result, power_result)
}

#[cfg(target_arch = "x86_64")]
#[rite]
fn linear_to_srgb_mt(token: Desktop64, linear: mt_f32x8) -> mt_f32x8 {
    let zero = mt_f32x8::zero(token);
    let one = mt_f32x8::splat(token, 1.0);
    let linear = linear.max(zero).min(one);

    let linear_result = linear * mt_f32x8::splat(token, MT_TWELVE_92);

    // sqrt transform + degree-15 Chebyshev polynomial (Estrin evaluation)
    let s = linear.sqrt();
    let u = s.mul_add(
        mt_f32x8::splat(token, L2S_INV_HW),
        mt_f32x8::splat(token, L2S_BIAS),
    );
    let u2 = u * u;
    let u4 = u2 * u2;
    let u_8 = u4 * u4;
    let p01 = mt_f32x8::splat(token, L2S_C1).mul_add(u, mt_f32x8::splat(token, L2S_C0));
    let p23 = mt_f32x8::splat(token, L2S_C3).mul_add(u, mt_f32x8::splat(token, L2S_C2));
    let p45 = mt_f32x8::splat(token, L2S_C5).mul_add(u, mt_f32x8::splat(token, L2S_C4));
    let p67 = mt_f32x8::splat(token, L2S_C7).mul_add(u, mt_f32x8::splat(token, L2S_C6));
    let p89 = mt_f32x8::splat(token, L2S_C9).mul_add(u, mt_f32x8::splat(token, L2S_C8));
    let pab = mt_f32x8::splat(token, L2S_C11).mul_add(u, mt_f32x8::splat(token, L2S_C10));
    let pcd = mt_f32x8::splat(token, L2S_C13).mul_add(u, mt_f32x8::splat(token, L2S_C12));
    let pef = mt_f32x8::splat(token, L2S_C15).mul_add(u, mt_f32x8::splat(token, L2S_C14));
    let p0123 = p23.mul_add(u2, p01);
    let p4567 = p67.mul_add(u2, p45);
    let p89ab = pab.mul_add(u2, p89);
    let pcdef = pef.mul_add(u2, pcd);
    let p0_7 = p4567.mul_add(u4, p0123);
    let p8_f = pcdef.mul_add(u4, p89ab);
    let power_result = p8_f.mul_add(u_8, p0_7);

    let mask = linear.simd_lt(mt_f32x8::splat(token, MT_LINEAR_THRESHOLD));
    mt_f32x8::blend(mask, linear_result, power_result)
}

#[cfg(target_arch = "x86_64")]
#[rite]
fn gamma_to_linear_mt(token: Desktop64, encoded: mt_f32x8, gamma: f32) -> mt_f32x8 {
    let zero = mt_f32x8::zero(token);
    let one = mt_f32x8::splat(token, 1.0);
    let encoded = encoded.max(zero).min(one);
    encoded.pow_midp(gamma)
}

#[cfg(target_arch = "x86_64")]
#[rite]
fn linear_to_gamma_mt(token: Desktop64, linear: mt_f32x8, gamma: f32) -> mt_f32x8 {
    let zero = mt_f32x8::zero(token);
    let one = mt_f32x8::splat(token, 1.0);
    let linear = linear.max(zero).min(one);
    linear.pow_midp(1.0 / gamma)
}

// ============================================================================
// x8 Dispatch Functions - Runtime CPU feature detection
// ============================================================================

#[cfg(target_arch = "x86_64")]
#[arcane]
fn srgb_to_linear_x8_tier_v3(token: Desktop64, srgb: f32x8) -> f32x8 {
    let arr: [f32; 8] = srgb.into();
    let v = mt_f32x8::from_array(token, arr);
    let result = srgb_to_linear_mt(token, v);
    f32x8::from(result.to_array())
}

fn srgb_to_linear_x8_tier_scalar(_token: ScalarToken, srgb: f32x8) -> f32x8 {
    srgb_to_linear_x8_inline(srgb)
}

/// Convert 8 sRGB f32 values to linear (with CPU dispatch).
///
/// This variant uses runtime CPU feature detection to select the optimal
/// implementation. Use [`srgb_to_linear_x8_inline`] inside your own
/// `#[magetypes]` functions to avoid double dispatch.
///
/// Input values are clamped to \[0, 1\].
#[inline]
pub fn srgb_to_linear_x8_dispatch(srgb: f32x8) -> f32x8 {
    incant!(srgb_to_linear_x8_tier(srgb), [v3])
}

#[cfg(target_arch = "x86_64")]
#[arcane]
fn linear_to_srgb_x8_tier_v3(token: Desktop64, linear: f32x8) -> f32x8 {
    let arr: [f32; 8] = linear.into();
    let v = mt_f32x8::from_array(token, arr);
    let result = linear_to_srgb_mt(token, v);
    f32x8::from(result.to_array())
}

fn linear_to_srgb_x8_tier_scalar(_token: ScalarToken, linear: f32x8) -> f32x8 {
    linear_to_srgb_x8_inline(linear)
}

/// Convert 8 linear f32 values to sRGB (with CPU dispatch).
///
/// This variant uses runtime CPU feature detection to select the optimal
/// implementation. Use [`linear_to_srgb_x8_inline`] inside your own
/// `#[magetypes]` functions to avoid double dispatch.
///
/// Input values are clamped to \[0, 1\].
#[inline]
pub fn linear_to_srgb_x8_dispatch(linear: f32x8) -> f32x8 {
    incant!(linear_to_srgb_x8_tier(linear), [v3])
}

/// Convert 8 linear f32 values to sRGB u8 (LUT-based, no dispatch needed).
#[inline]
pub fn linear_to_srgb_u8_x8_dispatch(linear: f32x8) -> [u8; 8] {
    linear_to_srgb_u8_x8_inline(linear)
}

#[cfg(target_arch = "x86_64")]
#[arcane]
fn gamma_to_linear_x8_tier_v3(token: Desktop64, encoded: f32x8, gamma: f32) -> f32x8 {
    let arr: [f32; 8] = encoded.into();
    let v = mt_f32x8::from_array(token, arr);
    let result = gamma_to_linear_mt(token, v, gamma);
    f32x8::from(result.to_array())
}

fn gamma_to_linear_x8_tier_scalar(_token: ScalarToken, encoded: f32x8, gamma: f32) -> f32x8 {
    gamma_to_linear_x8_inline(encoded, gamma)
}

/// Convert 8 gamma-encoded f32 values to linear (with CPU dispatch).
#[inline]
pub fn gamma_to_linear_x8_dispatch(encoded: f32x8, gamma: f32) -> f32x8 {
    incant!(gamma_to_linear_x8_tier(encoded, gamma), [v3])
}

#[cfg(target_arch = "x86_64")]
#[arcane]
fn linear_to_gamma_x8_tier_v3(token: Desktop64, linear: f32x8, gamma: f32) -> f32x8 {
    let arr: [f32; 8] = linear.into();
    let v = mt_f32x8::from_array(token, arr);
    let result = linear_to_gamma_mt(token, v, gamma);
    f32x8::from(result.to_array())
}

fn linear_to_gamma_x8_tier_scalar(_token: ScalarToken, linear: f32x8, gamma: f32) -> f32x8 {
    linear_to_gamma_x8_inline(linear, gamma)
}

/// Convert 8 linear f32 values to gamma-encoded (with CPU dispatch).
#[inline]
pub fn linear_to_gamma_x8_dispatch(linear: f32x8, gamma: f32) -> f32x8 {
    incant!(linear_to_gamma_x8_tier(linear, gamma), [v3])
}

// ============================================================================
// x8 Default Functions - Calls inline variant, compiler decides inlining
// ============================================================================

/// Convert 8 sRGB f32 values to linear.
///
/// This is the default variant that calls the inline implementation.
/// Use `_dispatch` for guaranteed CPU feature detection, or `_inline`
/// inside your own `#[magetypes]` functions.
///
/// Input values are clamped to \[0, 1\].
///
/// # Example
/// ```
/// use linear_srgb::simd::srgb_to_linear_x8;
/// use wide::f32x8;
///
/// let srgb = f32x8::from([0.0, 0.25, 0.5, 0.75, 1.0, 0.1, 0.9, 0.5]);
/// let linear = srgb_to_linear_x8(srgb);
/// ```
#[inline]
pub fn srgb_to_linear_x8(srgb: f32x8) -> f32x8 {
    srgb_to_linear_x8_inline(srgb)
}

/// Convert 8 linear f32 values to sRGB.
///
/// This is the default variant that calls the inline implementation.
/// Use `_dispatch` for guaranteed CPU feature detection, or `_inline`
/// inside your own `#[magetypes]` functions.
///
/// Input values are clamped to \[0, 1\].
///
/// # Example
/// ```
/// use linear_srgb::simd::linear_to_srgb_x8;
/// use wide::f32x8;
///
/// let linear = f32x8::from([0.0, 0.1, 0.2, 0.5, 1.0, 0.01, 0.05, 0.8]);
/// let srgb = linear_to_srgb_x8(linear);
/// ```
#[inline]
pub fn linear_to_srgb_x8(linear: f32x8) -> f32x8 {
    linear_to_srgb_x8_inline(linear)
}

/// Convert 8 sRGB u8 values to linear f32 using LUT lookup.
///
/// This is the fastest method for u8 input as it uses a precomputed lookup table.
///
/// # Example
/// ```
/// use linear_srgb::simd::srgb_u8_to_linear_x8;
///
/// let srgb = [0u8, 64, 128, 192, 255, 32, 96, 160];
/// let linear = srgb_u8_to_linear_x8(srgb);
/// ```
#[inline]
pub fn srgb_u8_to_linear_x8(srgb: [u8; 8]) -> f32x8 {
    let lut = get_lut();
    f32x8::from([
        lut[srgb[0] as usize],
        lut[srgb[1] as usize],
        lut[srgb[2] as usize],
        lut[srgb[3] as usize],
        lut[srgb[4] as usize],
        lut[srgb[5] as usize],
        lut[srgb[6] as usize],
        lut[srgb[7] as usize],
    ])
}

/// Convert 8 linear f32 values to sRGB u8.
///
/// Input values are clamped to \[0, 1\], output is rounded to nearest u8.
///
/// # Example
/// ```
/// use linear_srgb::simd::linear_to_srgb_u8_x8;
/// use wide::f32x8;
///
/// let linear = f32x8::from([0.0, 0.1, 0.2, 0.5, 1.0, 0.01, 0.05, 0.8]);
/// let srgb = linear_to_srgb_u8_x8(linear);
/// ```
#[inline]
pub fn linear_to_srgb_u8_x8(linear: f32x8) -> [u8; 8] {
    linear_to_srgb_u8_x8_inline(linear)
}

/// Convert 8 gamma-encoded f32 values to linear.
///
/// # Example
/// ```
/// use linear_srgb::simd::gamma_to_linear_x8;
/// use wide::f32x8;
///
/// let encoded = f32x8::from([0.0, 0.25, 0.5, 0.75, 1.0, 0.1, 0.9, 0.5]);
/// let linear = gamma_to_linear_x8(encoded, 2.2);
/// ```
#[inline]
pub fn gamma_to_linear_x8(encoded: f32x8, gamma: f32) -> f32x8 {
    gamma_to_linear_x8_inline(encoded, gamma)
}

/// Convert 8 linear f32 values to gamma-encoded.
///
/// # Example
/// ```
/// use linear_srgb::simd::linear_to_gamma_x8;
/// use wide::f32x8;
///
/// let linear = f32x8::from([0.0, 0.1, 0.2, 0.5, 1.0, 0.01, 0.05, 0.8]);
/// let encoded = linear_to_gamma_x8(linear, 2.2);
/// ```
#[inline]
pub fn linear_to_gamma_x8(linear: f32x8, gamma: f32) -> f32x8 {
    linear_to_gamma_x8_inline(linear, gamma)
}

// ============================================================================
// Slice Functions - Process entire slices
// ============================================================================

#[cfg(target_arch = "x86_64")]
#[arcane]
fn srgb_to_linear_slice_tier_v3(token: Desktop64, values: &mut [f32]) {
    let (chunks, remainder) = values.as_chunks_mut::<8>();

    for chunk in chunks {
        let v = mt_f32x8::from_array(token, *chunk);
        let result = srgb_to_linear_mt(token, v);
        *chunk = result.to_array();
    }

    for v in remainder {
        *v = crate::scalar::srgb_to_linear(*v);
    }
}

fn srgb_to_linear_slice_tier_scalar(_token: ScalarToken, values: &mut [f32]) {
    for v in values.iter_mut() {
        *v = crate::scalar::srgb_to_linear(*v);
    }
}

/// Convert sRGB f32 values to linear in-place.
///
/// Processes 8 values at a time using SIMD, with scalar fallback for remainder.
///
/// # Example
/// ```
/// use linear_srgb::simd::srgb_to_linear_slice;
///
/// let mut values = vec![0.0f32, 0.25, 0.5, 0.75, 1.0];
/// srgb_to_linear_slice(&mut values);
/// ```
#[inline]
pub fn srgb_to_linear_slice(values: &mut [f32]) {
    incant!(srgb_to_linear_slice_tier(values), [v3])
}

#[cfg(target_arch = "x86_64")]
#[arcane]
fn linear_to_srgb_slice_tier_v3(token: Desktop64, values: &mut [f32]) {
    let (chunks, remainder) = values.as_chunks_mut::<8>();

    for chunk in chunks {
        let v = mt_f32x8::from_array(token, *chunk);
        let result = linear_to_srgb_mt(token, v);
        *chunk = result.to_array();
    }

    for v in remainder {
        *v = crate::scalar::linear_to_srgb(*v);
    }
}

fn linear_to_srgb_slice_tier_scalar(_token: ScalarToken, values: &mut [f32]) {
    for v in values.iter_mut() {
        *v = crate::scalar::linear_to_srgb(*v);
    }
}

/// Convert linear f32 values to sRGB in-place.
///
/// Processes 8 values at a time using SIMD, with scalar fallback for remainder.
///
/// # Example
/// ```
/// use linear_srgb::simd::linear_to_srgb_slice;
///
/// let mut values = vec![0.0f32, 0.1, 0.2, 0.5, 1.0];
/// linear_to_srgb_slice(&mut values);
/// ```
#[inline]
pub fn linear_to_srgb_slice(values: &mut [f32]) {
    incant!(linear_to_srgb_slice_tier(values), [v3])
}

/// Convert sRGB u8 values to linear f32.
///
/// Uses a precomputed LUT for each u8 value, processed in SIMD batches of 8.
///
/// # Panics
/// Panics if `input.len() != output.len()`.
///
/// # Example
/// ```
/// use linear_srgb::simd::srgb_u8_to_linear_slice;
///
/// let input: Vec<u8> = (0..=255).collect();
/// let mut output = vec![0.0f32; 256];
/// srgb_u8_to_linear_slice(&input, &mut output);
/// ```
#[inline]
pub fn srgb_u8_to_linear_slice(input: &[u8], output: &mut [f32]) {
    assert_eq!(input.len(), output.len());
    let lut = get_lut();

    let (in_chunks, in_remainder) = input.as_chunks::<8>();
    let (out_chunks, out_remainder) = output.as_chunks_mut::<8>();

    for (inp, out) in in_chunks.iter().zip(out_chunks.iter_mut()) {
        *out = [
            lut[inp[0] as usize],
            lut[inp[1] as usize],
            lut[inp[2] as usize],
            lut[inp[3] as usize],
            lut[inp[4] as usize],
            lut[inp[5] as usize],
            lut[inp[6] as usize],
            lut[inp[7] as usize],
        ];
    }

    for (inp, out) in in_remainder.iter().zip(out_remainder.iter_mut()) {
        *out = lut[*inp as usize];
    }
}

/// Convert linear f32 values to sRGB u8.
///
/// Processes 8 values at a time using SIMD, with scalar fallback for remainder.
///
/// # Panics
/// Panics if `input.len() != output.len()`.
///
/// # Example
/// ```
/// use linear_srgb::simd::linear_to_srgb_u8_slice;
///
/// let input: Vec<f32> = (0..=255).map(|i| i as f32 / 255.0).collect();
/// let mut output = vec![0u8; 256];
/// linear_to_srgb_u8_slice(&input, &mut output);
/// ```
pub fn linear_to_srgb_u8_slice(input: &[f32], output: &mut [u8]) {
    assert_eq!(input.len(), output.len());

    let lut = &crate::const_luts::LINEAR_TO_SRGB_U8;

    // Process 8 at a time using SIMD for index computation
    let (in_chunks, in_remainder) = input.as_chunks::<8>();
    let (out_chunks, out_remainder) = output.as_chunks_mut::<8>();

    for (inp, out) in in_chunks.iter().zip(out_chunks.iter_mut()) {
        let linear = f32x8::from(*inp);
        let clamped = linear.max(ZERO).min(ONE);
        let scaled = clamped * f32x8::splat(4095.0) + HALF;
        let arr: [f32; 8] = scaled.into();
        *out = [
            lut[arr[0] as usize & 0xFFF],
            lut[arr[1] as usize & 0xFFF],
            lut[arr[2] as usize & 0xFFF],
            lut[arr[3] as usize & 0xFFF],
            lut[arr[4] as usize & 0xFFF],
            lut[arr[5] as usize & 0xFFF],
            lut[arr[6] as usize & 0xFFF],
            lut[arr[7] as usize & 0xFFF],
        ];
    }

    for (inp, out) in in_remainder.iter().zip(out_remainder.iter_mut()) {
        *out = crate::scalar::linear_to_srgb_u8(*inp);
    }
}

// ============================================================================
// u16 Batch Functions (LUT-based)
// ============================================================================

/// Convert sRGB u16 values to linear f32 using a 65536-entry const LUT.
///
/// Pure table lookup, no math. The LUT is 256KB.
///
/// # Panics
/// Panics if `input.len() != output.len()`.
pub fn srgb_u16_to_linear_slice(input: &[u16], output: &mut [f32]) {
    assert_eq!(input.len(), output.len());
    let lut = &crate::const_luts_u16::SRGB_U16_TO_LINEAR_F32;

    let (in_chunks, in_remainder) = input.as_chunks::<8>();
    let (out_chunks, out_remainder) = output.as_chunks_mut::<8>();

    for (inp, out) in in_chunks.iter().zip(out_chunks.iter_mut()) {
        *out = [
            lut[inp[0] as usize],
            lut[inp[1] as usize],
            lut[inp[2] as usize],
            lut[inp[3] as usize],
            lut[inp[4] as usize],
            lut[inp[5] as usize],
            lut[inp[6] as usize],
            lut[inp[7] as usize],
        ];
    }

    for (inp, out) in in_remainder.iter().zip(out_remainder.iter_mut()) {
        *out = lut[*inp as usize];
    }
}

/// Convert linear f32 values to sRGB u16 using a 65537-entry const LUT.
///
/// # Panics
/// Panics if `input.len() != output.len()`.
pub fn linear_to_srgb_u16_slice(input: &[f32], output: &mut [u16]) {
    assert_eq!(input.len(), output.len());
    let lut = &crate::const_luts_u16::LINEAR_TO_SRGB_U16_65536;

    let (in_chunks, in_remainder) = input.as_chunks::<8>();
    let (out_chunks, out_remainder) = output.as_chunks_mut::<8>();

    for (inp, out) in in_chunks.iter().zip(out_chunks.iter_mut()) {
        let linear = f32x8::from(*inp);
        let clamped = linear.max(ZERO).min(ONE);
        let scaled = clamped * f32x8::splat(65536.0) + HALF;
        let arr: [f32; 8] = scaled.into();
        *out = [
            lut[arr[0] as usize],
            lut[arr[1] as usize],
            lut[arr[2] as usize],
            lut[arr[3] as usize],
            lut[arr[4] as usize],
            lut[arr[5] as usize],
            lut[arr[6] as usize],
            lut[arr[7] as usize],
        ];
    }

    for (inp, out) in in_remainder.iter().zip(out_remainder.iter_mut()) {
        *out = crate::scalar::linear_to_srgb_u16(*inp);
    }
}

// ============================================================================
// Custom Gamma Slice Functions
// ============================================================================

#[cfg(target_arch = "x86_64")]
#[arcane]
fn gamma_to_linear_slice_tier_v3(token: Desktop64, values: &mut [f32], gamma: f32) {
    let (chunks, remainder) = values.as_chunks_mut::<8>();

    for chunk in chunks {
        let v = mt_f32x8::from_array(token, *chunk);
        let result = gamma_to_linear_mt(token, v, gamma);
        *chunk = result.to_array();
    }

    for v in remainder {
        *v = crate::scalar::gamma_to_linear(*v, gamma);
    }
}

fn gamma_to_linear_slice_tier_scalar(_token: ScalarToken, values: &mut [f32], gamma: f32) {
    for v in values.iter_mut() {
        *v = crate::scalar::gamma_to_linear(*v, gamma);
    }
}

/// Convert gamma-encoded f32 values to linear in-place using a custom gamma.
///
/// Processes 8 values at a time using SIMD, with scalar fallback for remainder.
///
/// # Example
/// ```
/// use linear_srgb::simd::gamma_to_linear_slice;
///
/// let mut values = vec![0.0f32, 0.25, 0.5, 0.75, 1.0];
/// gamma_to_linear_slice(&mut values, 2.2);
/// ```
#[inline]
pub fn gamma_to_linear_slice(values: &mut [f32], gamma: f32) {
    incant!(gamma_to_linear_slice_tier(values, gamma), [v3])
}

#[cfg(target_arch = "x86_64")]
#[arcane]
fn linear_to_gamma_slice_tier_v3(token: Desktop64, values: &mut [f32], gamma: f32) {
    let (chunks, remainder) = values.as_chunks_mut::<8>();

    for chunk in chunks {
        let v = mt_f32x8::from_array(token, *chunk);
        let result = linear_to_gamma_mt(token, v, gamma);
        *chunk = result.to_array();
    }

    for v in remainder {
        *v = crate::scalar::linear_to_gamma(*v, gamma);
    }
}

fn linear_to_gamma_slice_tier_scalar(_token: ScalarToken, values: &mut [f32], gamma: f32) {
    for v in values.iter_mut() {
        *v = crate::scalar::linear_to_gamma(*v, gamma);
    }
}

/// Convert linear f32 values to gamma-encoded in-place using a custom gamma.
///
/// Processes 8 values at a time using SIMD, with scalar fallback for remainder.
///
/// # Example
/// ```
/// use linear_srgb::simd::linear_to_gamma_slice;
///
/// let mut values = vec![0.0f32, 0.1, 0.2, 0.5, 1.0];
/// linear_to_gamma_slice(&mut values, 2.2);
/// ```
#[inline]
pub fn linear_to_gamma_slice(values: &mut [f32], gamma: f32) {
    incant!(linear_to_gamma_slice_tier(values, gamma), [v3])
}

// ============================================================================
// f32x8 Slice Functions (for pre-aligned SIMD data)
// ============================================================================

#[cfg(target_arch = "x86_64")]
#[arcane]
fn srgb_to_linear_x8_slice_tier_v3(token: Desktop64, values: &mut [f32x8]) {
    for v in values.iter_mut() {
        let arr: [f32; 8] = (*v).into();
        let mt_v = mt_f32x8::from_array(token, arr);
        let result = srgb_to_linear_mt(token, mt_v);
        *v = f32x8::from(result.to_array());
    }
}

fn srgb_to_linear_x8_slice_tier_scalar(_token: ScalarToken, values: &mut [f32x8]) {
    for v in values.iter_mut() {
        *v = srgb_to_linear_x8_inline(*v);
    }
}

/// Convert sRGB f32x8 values to linear in-place.
///
/// For data already structured as `f32x8` slices. If you have `&mut [f32]`,
/// use [`srgb_to_linear_slice`] instead which handles remainders automatically.
///
/// # Example
/// ```
/// use linear_srgb::simd::srgb_to_linear_x8_slice;
/// use wide::f32x8;
///
/// let mut values = vec![f32x8::splat(0.5); 100];
/// srgb_to_linear_x8_slice(&mut values);
/// ```
#[inline]
pub fn srgb_to_linear_x8_slice(values: &mut [f32x8]) {
    incant!(srgb_to_linear_x8_slice_tier(values), [v3])
}

#[cfg(target_arch = "x86_64")]
#[arcane]
fn linear_to_srgb_x8_slice_tier_v3(token: Desktop64, values: &mut [f32x8]) {
    for v in values.iter_mut() {
        let arr: [f32; 8] = (*v).into();
        let mt_v = mt_f32x8::from_array(token, arr);
        let result = linear_to_srgb_mt(token, mt_v);
        *v = f32x8::from(result.to_array());
    }
}

fn linear_to_srgb_x8_slice_tier_scalar(_token: ScalarToken, values: &mut [f32x8]) {
    for v in values.iter_mut() {
        *v = linear_to_srgb_x8_inline(*v);
    }
}

/// Convert linear f32x8 values to sRGB in-place.
///
/// For data already structured as `f32x8` slices. If you have `&mut [f32]`,
/// use [`linear_to_srgb_slice`] instead which handles remainders automatically.
///
/// # Example
/// ```
/// use linear_srgb::simd::linear_to_srgb_x8_slice;
/// use wide::f32x8;
///
/// let mut values = vec![f32x8::splat(0.5); 100];
/// linear_to_srgb_x8_slice(&mut values);
/// ```
#[inline]
pub fn linear_to_srgb_x8_slice(values: &mut [f32x8]) {
    incant!(linear_to_srgb_x8_slice_tier(values), [v3])
}

#[cfg(target_arch = "x86_64")]
#[arcane]
fn gamma_to_linear_x8_slice_tier_v3(token: Desktop64, values: &mut [f32x8], gamma: f32) {
    for v in values.iter_mut() {
        let arr: [f32; 8] = (*v).into();
        let mt_v = mt_f32x8::from_array(token, arr);
        let result = gamma_to_linear_mt(token, mt_v, gamma);
        *v = f32x8::from(result.to_array());
    }
}

fn gamma_to_linear_x8_slice_tier_scalar(_token: ScalarToken, values: &mut [f32x8], gamma: f32) {
    for v in values.iter_mut() {
        *v = gamma_to_linear_x8_inline(*v, gamma);
    }
}

/// Convert gamma-encoded f32x8 values to linear in-place using a custom gamma.
///
/// For data already structured as `f32x8` slices. If you have `&mut [f32]`,
/// use [`gamma_to_linear_slice`] instead which handles remainders automatically.
///
/// # Example
/// ```
/// use linear_srgb::simd::gamma_to_linear_x8_slice;
/// use wide::f32x8;
///
/// let mut values = vec![f32x8::splat(0.5); 100];
/// gamma_to_linear_x8_slice(&mut values, 2.2);
/// ```
#[inline]
pub fn gamma_to_linear_x8_slice(values: &mut [f32x8], gamma: f32) {
    incant!(gamma_to_linear_x8_slice_tier(values, gamma), [v3])
}

#[cfg(target_arch = "x86_64")]
#[arcane]
fn linear_to_gamma_x8_slice_tier_v3(token: Desktop64, values: &mut [f32x8], gamma: f32) {
    for v in values.iter_mut() {
        let arr: [f32; 8] = (*v).into();
        let mt_v = mt_f32x8::from_array(token, arr);
        let result = linear_to_gamma_mt(token, mt_v, gamma);
        *v = f32x8::from(result.to_array());
    }
}

fn linear_to_gamma_x8_slice_tier_scalar(_token: ScalarToken, values: &mut [f32x8], gamma: f32) {
    for v in values.iter_mut() {
        *v = linear_to_gamma_x8_inline(*v, gamma);
    }
}

/// Convert linear f32x8 values to gamma-encoded in-place using a custom gamma.
///
/// For data already structured as `f32x8` slices. If you have `&mut [f32]`,
/// use [`linear_to_gamma_slice`] instead which handles remainders automatically.
///
/// # Example
/// ```
/// use linear_srgb::simd::linear_to_gamma_x8_slice;
/// use wide::f32x8;
///
/// let mut values = vec![f32x8::splat(0.2); 100];
/// linear_to_gamma_x8_slice(&mut values, 2.2);
/// ```
#[inline]
pub fn linear_to_gamma_x8_slice(values: &mut [f32x8], gamma: f32) {
    incant!(linear_to_gamma_x8_slice_tier(values, gamma), [v3])
}

// ============================================================================
// f32x8 Slice Inline Functions (for use inside caller's magetypes code)
// ============================================================================

/// Convert sRGB f32x8 values to linear in-place (always inlined).
///
/// Use this variant inside your own `#[magetypes]` functions to avoid
/// double dispatch overhead. For standalone calls, use [`srgb_to_linear_x8_slice`].
#[inline(always)]
pub fn srgb_to_linear_x8_slice_inline(values: &mut [f32x8]) {
    for v in values.iter_mut() {
        *v = srgb_to_linear_x8_inline(*v);
    }
}

/// Convert linear f32x8 values to sRGB in-place (always inlined).
///
/// Use this variant inside your own `#[magetypes]` functions to avoid
/// double dispatch overhead. For standalone calls, use [`linear_to_srgb_x8_slice`].
#[inline(always)]
pub fn linear_to_srgb_x8_slice_inline(values: &mut [f32x8]) {
    for v in values.iter_mut() {
        *v = linear_to_srgb_x8_inline(*v);
    }
}

/// Convert gamma-encoded f32x8 values to linear in-place (always inlined).
///
/// Use this variant inside your own `#[magetypes]` functions to avoid
/// double dispatch overhead. For standalone calls, use [`gamma_to_linear_x8_slice`].
#[inline(always)]
pub fn gamma_to_linear_x8_slice_inline(values: &mut [f32x8], gamma: f32) {
    for v in values.iter_mut() {
        *v = gamma_to_linear_x8_inline(*v, gamma);
    }
}

/// Convert linear f32x8 values to gamma-encoded in-place (always inlined).
///
/// Use this variant inside your own `#[magetypes]` functions to avoid
/// double dispatch overhead. For standalone calls, use [`linear_to_gamma_x8_slice`].
#[inline(always)]
pub fn linear_to_gamma_x8_slice_inline(values: &mut [f32x8], gamma: f32) {
    for v in values.iter_mut() {
        *v = linear_to_gamma_x8_inline(*v, gamma);
    }
}

// ============================================================================
// Tests
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    #[cfg(not(feature = "std"))]
    use alloc::{vec, vec::Vec};

    // ---- x8 function tests ----

    #[test]
    #[allow(deprecated)]
    fn test_srgb_to_linear_x8() {
        let input = [0.0f32, 0.25, 0.5, 0.75, 1.0, 0.1, 0.9, 0.04];
        let result = srgb_to_linear_x8(f32x8::from(input));
        let result_arr: [f32; 8] = result.into();

        for (i, &inp) in input.iter().enumerate() {
            let expected = crate::scalar::srgb_to_linear(inp);
            assert!(
                (result_arr[i] - expected).abs() < 1e-5,
                "srgb_to_linear_x8 mismatch at {}: got {}, expected {}",
                i,
                result_arr[i],
                expected
            );
        }
    }

    #[test]
    fn test_linear_to_srgb_x8() {
        let input = [0.0f32, 0.1, 0.2, 0.5, 1.0, 0.01, 0.001, 0.8];
        let result = linear_to_srgb_x8(f32x8::from(input));
        let result_arr: [f32; 8] = result.into();

        for (i, &inp) in input.iter().enumerate() {
            let expected = crate::scalar::linear_to_srgb(inp);
            assert!(
                (result_arr[i] - expected).abs() < 1e-5,
                "linear_to_srgb_x8 mismatch at {}: got {}, expected {}",
                i,
                result_arr[i],
                expected
            );
        }
    }

    #[test]
    #[allow(deprecated)]
    fn test_srgb_u8_to_linear_x8() {
        let input: [u8; 8] = [0, 64, 128, 192, 255, 32, 96, 160];
        let result = srgb_u8_to_linear_x8(input);
        let result_arr: [f32; 8] = result.into();

        for (i, &inp) in input.iter().enumerate() {
            let expected = crate::scalar::srgb_u8_to_linear(inp);
            assert!(
                (result_arr[i] - expected).abs() < 1e-6,
                "srgb_u8_to_linear_x8 mismatch at {}: got {}, expected {}",
                i,
                result_arr[i],
                expected
            );
        }
    }

    #[test]
    fn test_linear_to_srgb_u8_x8() {
        let input = [0.0f32, 0.1, 0.2, 0.5, 1.0, 0.01, 0.05, 0.8];
        let result = linear_to_srgb_u8_x8(f32x8::from(input));

        for (i, &inp) in input.iter().enumerate() {
            let expected = (crate::scalar::linear_to_srgb(inp) * 255.0 + 0.5) as u8;
            assert!(
                (result[i] as i16 - expected as i16).abs() <= 1,
                "linear_to_srgb_u8_x8 mismatch at {}: got {}, expected {}",
                i,
                result[i],
                expected
            );
        }
    }

    // ---- Slice function tests ----

    #[test]
    fn test_srgb_to_linear_slice() {
        let mut values: Vec<f32> = (0..100).map(|i| i as f32 / 99.0).collect();
        let expected: Vec<f32> = values
            .iter()
            .map(|&v| crate::scalar::srgb_to_linear(v))
            .collect();

        srgb_to_linear_slice(&mut values);

        for (i, (&got, &exp)) in values.iter().zip(expected.iter()).enumerate() {
            assert!(
                (got - exp).abs() < 1e-5,
                "srgb_to_linear_slice mismatch at {}: got {}, expected {}",
                i,
                got,
                exp
            );
        }
    }

    #[test]
    fn test_linear_to_srgb_slice() {
        let mut values: Vec<f32> = (0..100).map(|i| i as f32 / 99.0).collect();
        let expected: Vec<f32> = values
            .iter()
            .map(|&v| crate::scalar::linear_to_srgb(v))
            .collect();

        linear_to_srgb_slice(&mut values);

        for (i, (&got, &exp)) in values.iter().zip(expected.iter()).enumerate() {
            assert!(
                (got - exp).abs() < 1e-5,
                "linear_to_srgb_slice mismatch at {}: got {}, expected {}",
                i,
                got,
                exp
            );
        }
    }

    #[test]
    #[allow(deprecated)]
    fn test_srgb_u8_to_linear_slice() {
        let input: Vec<u8> = (0..=255).collect();
        let mut output = vec![0.0f32; 256];

        srgb_u8_to_linear_slice(&input, &mut output);

        for (i, &out) in output.iter().enumerate() {
            let expected = crate::scalar::srgb_u8_to_linear(i as u8);
            assert!(
                (out - expected).abs() < 1e-6,
                "srgb_u8_to_linear_slice mismatch at {}: got {}, expected {}",
                i,
                out,
                expected
            );
        }
    }

    #[test]
    fn test_linear_to_srgb_u8_slice() {
        let input: Vec<f32> = (0..=255).map(|i| i as f32 / 255.0).collect();
        let mut output = vec![0u8; 256];

        linear_to_srgb_u8_slice(&input, &mut output);

        for i in 0..256 {
            let expected = (crate::scalar::linear_to_srgb(input[i]) * 255.0 + 0.5) as u8;
            assert!(
                (output[i] as i16 - expected as i16).abs() <= 1,
                "linear_to_srgb_u8_slice mismatch at {}: got {}, expected {}",
                i,
                output[i],
                expected
            );
        }
    }

    // ---- Roundtrip tests ----

    #[test]
    fn test_f32_roundtrip() {
        let mut values: Vec<f32> = (0..1000).map(|i| i as f32 / 999.0).collect();
        let original = values.clone();

        srgb_to_linear_slice(&mut values);
        linear_to_srgb_slice(&mut values);

        for (i, (&orig, &conv)) in original.iter().zip(values.iter()).enumerate() {
            assert!(
                (orig - conv).abs() < 1e-4,
                "f32 roundtrip failed at {}: {} -> {}",
                i,
                orig,
                conv
            );
        }
    }

    #[test]
    fn test_u8_roundtrip() {
        let input: Vec<u8> = (0..=255).collect();
        let mut linear = vec![0.0f32; 256];
        let mut back = vec![0u8; 256];

        srgb_u8_to_linear_slice(&input, &mut linear);
        linear_to_srgb_u8_slice(&linear, &mut back);

        for i in 0..256 {
            assert!(
                (input[i] as i16 - back[i] as i16).abs() <= 1,
                "u8 roundtrip failed at {}: {} -> {} -> {}",
                i,
                input[i],
                linear[i],
                back[i]
            );
        }
    }

    // ---- Edge case tests ----

    #[test]
    #[allow(deprecated)]
    fn test_clamping() {
        // Test that out-of-range values are clamped
        let input = f32x8::from([-0.5, -0.1, 0.0, 0.5, 1.0, 1.5, 2.0, 10.0]);
        let result = srgb_to_linear_x8(input);
        let arr: [f32; 8] = result.into();

        assert_eq!(arr[0], 0.0, "negative should clamp to 0");
        assert_eq!(arr[1], 0.0, "negative should clamp to 0");
        assert!(arr[4] > 0.99 && arr[4] <= 1.0, "1.0 should stay ~1.0");
        assert!(arr[5] > 0.99 && arr[5] <= 1.0, "values > 1 should clamp");
    }

    #[test]
    #[allow(deprecated)]
    fn test_linear_segment() {
        // Test values in the linear segment (< 0.04045)
        let input = f32x8::from([0.0, 0.01, 0.02, 0.03, 0.04, 0.005, 0.015, 0.035]);
        let result = srgb_to_linear_x8(input);
        let arr: [f32; 8] = result.into();
        let input_arr: [f32; 8] = input.into();

        for i in 0..8 {
            let expected = input_arr[i] / 12.92;
            assert!(
                (arr[i] - expected).abs() < 1e-6,
                "linear segment mismatch at {}: got {}, expected {}",
                i,
                arr[i],
                expected
            );
        }
    }

    /// Verify the const LUT stays in sync with the transfer function.
    /// Allows 1 ULP difference for cross-platform float variance (powf isn't
    /// perfectly deterministic across architectures).
    #[test]
    #[allow(deprecated)]
    fn test_lut_matches_transfer_function() {
        let lut = get_lut();
        for i in 0..=255u8 {
            let expected = crate::scalar::srgb_u8_to_linear(i);
            let got = lut[i as usize];
            let got_bits = got.to_bits();
            let expected_bits = expected.to_bits();
            let ulp_diff = (got_bits as i64 - expected_bits as i64).unsigned_abs();
            assert!(
                ulp_diff <= 1,
                "LUT[{}] = {} ({:08x}) differs by {} ULP from srgb_u8_to_linear({}) = {} ({:08x}). \
                 LUT needs regeneration if transfer constants changed.",
                i,
                got,
                got_bits,
                ulp_diff,
                i,
                expected,
                expected_bits
            );
        }
    }

    #[test]
    fn test_empty_slice() {
        let mut empty: Vec<f32> = vec![];
        srgb_to_linear_slice(&mut empty);
        assert!(empty.is_empty());

        let empty_u8: Vec<u8> = vec![];
        let mut empty_out: Vec<f32> = vec![];
        srgb_u8_to_linear_slice(&empty_u8, &mut empty_out);
    }

    #[test]
    fn test_non_multiple_of_8() {
        // Test slices that aren't multiples of 8
        for len in [1, 3, 7, 9, 15, 17, 100] {
            let mut values: Vec<f32> = (0..len).map(|i| i as f32 / len as f32).collect();
            let expected: Vec<f32> = values
                .iter()
                .map(|&v| crate::scalar::srgb_to_linear(v))
                .collect();

            srgb_to_linear_slice(&mut values);

            for (i, (&got, &exp)) in values.iter().zip(expected.iter()).enumerate() {
                assert!(
                    (got - exp).abs() < 1e-5,
                    "len={} mismatch at {}: got {}, expected {}",
                    len,
                    i,
                    got,
                    exp
                );
            }
        }
    }

    // ---- Custom gamma tests ----

    #[test]
    fn test_gamma_to_linear_x8() {
        let input = [0.0f32, 0.25, 0.5, 0.75, 1.0, 0.1, 0.9, 0.04];
        let gamma = 2.2f32;
        let result = gamma_to_linear_x8(f32x8::from(input), gamma);
        let result_arr: [f32; 8] = result.into();

        for (i, &inp) in input.iter().enumerate() {
            let expected = crate::scalar::gamma_to_linear(inp, gamma);
            assert!(
                (result_arr[i] - expected).abs() < 1e-5,
                "gamma_to_linear_x8 mismatch at {}: got {}, expected {}",
                i,
                result_arr[i],
                expected
            );
        }
    }

    #[test]
    fn test_linear_to_gamma_x8() {
        let input = [0.0f32, 0.1, 0.2, 0.5, 1.0, 0.01, 0.001, 0.8];
        let gamma = 2.2f32;
        let result = linear_to_gamma_x8(f32x8::from(input), gamma);
        let result_arr: [f32; 8] = result.into();

        for (i, &inp) in input.iter().enumerate() {
            let expected = crate::scalar::linear_to_gamma(inp, gamma);
            assert!(
                (result_arr[i] - expected).abs() < 1e-5,
                "linear_to_gamma_x8 mismatch at {}: got {}, expected {}",
                i,
                result_arr[i],
                expected
            );
        }
    }

    #[test]
    fn test_gamma_roundtrip_x8() {
        let input = [0.0f32, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99, 1.0];
        for gamma in [1.8f32, 2.0, 2.2, 2.4] {
            let linear = gamma_to_linear_x8(f32x8::from(input), gamma);
            let back = linear_to_gamma_x8(linear, gamma);
            let back_arr: [f32; 8] = back.into();

            for (i, &inp) in input.iter().enumerate() {
                assert!(
                    (inp - back_arr[i]).abs() < 1e-4,
                    "gamma {} roundtrip failed at {}: {} -> {}",
                    gamma,
                    i,
                    inp,
                    back_arr[i]
                );
            }
        }
    }

    #[test]
    fn test_gamma_slice_functions() {
        let gamma = 2.2f32;

        let mut values: Vec<f32> = (0..100).map(|i| i as f32 / 99.0).collect();
        let expected: Vec<f32> = values
            .iter()
            .map(|&v| crate::scalar::gamma_to_linear(v, gamma))
            .collect();

        gamma_to_linear_slice(&mut values, gamma);

        for (i, (&got, &exp)) in values.iter().zip(expected.iter()).enumerate() {
            assert!(
                (got - exp).abs() < 1e-5,
                "gamma_to_linear_slice mismatch at {}: got {}, expected {}",
                i,
                got,
                exp
            );
        }

        // Test linear_to_gamma_slice
        let expected_back: Vec<f32> = values
            .iter()
            .map(|&v| crate::scalar::linear_to_gamma(v, gamma))
            .collect();

        linear_to_gamma_slice(&mut values, gamma);

        for (i, (&got, &exp)) in values.iter().zip(expected_back.iter()).enumerate() {
            assert!(
                (got - exp).abs() < 1e-5,
                "linear_to_gamma_slice mismatch at {}: got {}, expected {}",
                i,
                got,
                exp
            );
        }
    }

    // ---- Permutation tests (archmage tier testing) ----

    #[test]
    fn srgb_roundtrip_all_tiers() {
        let report = archmage::testing::for_each_token_permutation(
            archmage::testing::CompileTimePolicy::Warn,
            |_perm| {
                let mut values: Vec<f32> = (0..100).map(|i| i as f32 / 99.0).collect();
                let original = values.clone();
                srgb_to_linear_slice(&mut values);
                linear_to_srgb_slice(&mut values);
                for (i, (&orig, &conv)) in original.iter().zip(values.iter()).enumerate() {
                    assert!(
                        (orig - conv).abs() < 1e-4,
                        "tier roundtrip failed at {i}: {orig} -> {conv}"
                    );
                }
            },
        );
        eprintln!("{report}");
    }
}
